{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merylmizell/ResNetForCTScans/blob/main/TrainingResNet152V3_Optimized7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbyasQRRgXjr",
        "outputId": "692f6c78-b38d-4db0-9c53-af36e94b516e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/664.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/664.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI4JvhOphCBL",
        "outputId": "8e2bb100-e4c5-47fe-afb6-cd8e7ca4ec3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 324, in run\n",
            "    session = self.get_default_session(options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 71, in get_default_session\n",
            "    self._session = self.enter_context(self._build_session(options))\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 100, in _build_session\n",
            "    session = PipSession(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 344, in __init__\n",
            "    self.headers[\"User-Agent\"] = user_agent()\n",
            "                                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 177, in user_agent\n",
            "    setuptools_dist = get_default_environment().get_distribution(\"setuptools\")\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
            "    return next(matches, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
            "    matches = (\n",
            "              ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 612, in iter_all_distributions\n",
            "    for dist in self._iter_distributions():\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 176, in _iter_distributions\n",
            "    yield from finder.find(location)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 79, in find\n",
            "    for dist, info_location in self._find_impl(location):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 64, in _find_impl\n",
            "    raw_name = get_dist_name(dist)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_compat.py\", line 52, in get_dist_name\n",
            "    name = cast(Any, dist).name\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 622, in name\n",
            "    return self.metadata['Name']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 56, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 466, in _parsegen\n",
            "    lines.append(line)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 73, in emit\n",
            "    if self.shouldRollover(record):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 191, in shouldRollover\n",
            "    if os.path.exists(self.baseFilename) and not os.path.isfile(self.baseFilename):\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen genericpath>\", line 30, in isfile\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lc06oLR3hJMs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import drive\n",
        "import logging\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs2ES80h0qp"
      },
      "source": [
        "# Custom dataset class\n",
        "class HemorrhageDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image = Image.open(row[\"png_path\"]).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "        labels = torch.tensor(row.iloc[1:-1].values, dtype=torch.float32)\n",
        "        return image, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMioYl_At6QH",
        "outputId": "dacec76d-3001-472f-d9a4-30f2a6657e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated file saved as: updated_train.csv\n",
            "Updated file saved as: updated_val.csv\n",
            "Updated file saved as: updated_test.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the file paths\n",
        "csv_files = [\"train.csv\", \"val.csv\", \"test.csv\"]  # Add or remove CSV files as needed\n",
        "old_path = \"C:\\\\Users\\\\Myers\\\\Desktop\\\\rsna-ihd-dataset_extracted\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed_images\\\\\"\n",
        "new_path = \"/content/drive/MyDrive/preprocessed_images5K/\"\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    # Load the CSV\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Replace the file paths in the 'png_path' column\n",
        "    df[\"png_path\"] = df[\"png_path\"].str.replace(old_path, new_path, regex=False)\n",
        "\n",
        "    # Save the updated CSV file (overwrite or create a new file)\n",
        "    updated_csv_file = f\"updated_{csv_file}\"  # Saves as 'updated_train.csv', etc.\n",
        "    df.to_csv(updated_csv_file, index=False)\n",
        "\n",
        "    print(f\"Updated file saved as: {updated_csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZjGeScpFh-1O"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv(\"/content/updated_test.csv\")  # Update path\n",
        "val_df = pd.read_csv(\"/content/updated_val.csv\")\n",
        "test_df = pd.read_csv(\"/content/updated_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "avKh4Be146_K"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDFRyE1vtmAM",
        "outputId": "8820b692-0b1e-4b4d-e3a3-dffade2266a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       dicom_id  subdural  epidural  subarachnoid  intraparenchymal  \\\n",
            "0  ID_01241a0ab       0.0       0.0           0.0               0.0   \n",
            "1  ID_042ab92ef       0.0       0.0           0.0               0.0   \n",
            "2  ID_03678fae1       0.0       0.0           0.0               0.0   \n",
            "3  ID_01ed2b6c3       0.0       0.0           0.0               0.0   \n",
            "4  ID_04e8cccc0       0.0       0.0           0.0               0.0   \n",
            "\n",
            "   intraventricular  any  none  \\\n",
            "0               0.0  0.0     1   \n",
            "1               0.0  0.0     1   \n",
            "2               0.0  0.0     1   \n",
            "3               0.0  0.0     1   \n",
            "4               0.0  0.0     1   \n",
            "\n",
            "                                            png_path  \n",
            "0  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "1  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "2  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "3  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "4  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "       dicom_id  subdural  epidural  subarachnoid  intraparenchymal  \\\n",
            "0  ID_01769589f       0.0       0.0           0.0               0.0   \n",
            "1  ID_04ae09d86       0.0       0.0           0.0               0.0   \n",
            "2  ID_02cce36ef       0.0       0.0           0.0               0.0   \n",
            "3  ID_025192b17       0.0       0.0           0.0               0.0   \n",
            "4  ID_01c43b144       0.0       0.0           0.0               0.0   \n",
            "\n",
            "   intraventricular  any  none  \\\n",
            "0               1.0  1.0     0   \n",
            "1               0.0  0.0     1   \n",
            "2               0.0  0.0     1   \n",
            "3               0.0  0.0     1   \n",
            "4               0.0  0.0     1   \n",
            "\n",
            "                                            png_path  \n",
            "0  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "1  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "2  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "3  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "4  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "       dicom_id  subdural  epidural  subarachnoid  intraparenchymal  \\\n",
            "0  ID_01241a0ab       0.0       0.0           0.0               0.0   \n",
            "1  ID_042ab92ef       0.0       0.0           0.0               0.0   \n",
            "2  ID_03678fae1       0.0       0.0           0.0               0.0   \n",
            "3  ID_01ed2b6c3       0.0       0.0           0.0               0.0   \n",
            "4  ID_04e8cccc0       0.0       0.0           0.0               0.0   \n",
            "\n",
            "   intraventricular  any  none  \\\n",
            "0               0.0  0.0     1   \n",
            "1               0.0  0.0     1   \n",
            "2               0.0  0.0     1   \n",
            "3               0.0  0.0     1   \n",
            "4               0.0  0.0     1   \n",
            "\n",
            "                                            png_path  \n",
            "0  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "1  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "2  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "3  /content/drive/MyDrive/preprocessed_images5K/I...  \n",
            "4  /content/drive/MyDrive/preprocessed_images5K/I...  \n"
          ]
        }
      ],
      "source": [
        "# prompt: head of both df\n",
        "\n",
        "print(train_df.head())\n",
        "print(val_df.head())\n",
        "print(test_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ujhc1-WYwOvC"
      },
      "outputs": [],
      "source": [
        "class HemorrhageDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image_path = row[\"png_path\"]\n",
        "\n",
        "        # Load grayscale image\n",
        "        image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "        image = self.transform(image)\n",
        "\n",
        "        # Extract labels and handle potential non-numeric values\n",
        "        labels = row.iloc[1:-1]  # Exclude dicom_id and png_path\n",
        "        labels = labels.apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert to numeric, replace NaNs with 0\n",
        "        labels = np.array(labels, dtype=np.float32)  # Convert to float32 NumPy array\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "\n",
        "        return image, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qUVqD4lr6om",
        "outputId": "a1d18505-ec42-4413-a0af-37464bd1e7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAf5SmX5LmL2",
        "outputId": "10e7bad5-1540-4638-8816-1df204d31e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed pos_weights: tensor([ 11.5000, 186.5000,  20.4286,  19.8333,  24.0000,   4.9524,   0.2019],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Define the correct label columns\n",
        "label_columns = ['subdural', 'epidural', 'subarachnoid', 'intraparenchymal', 'intraventricular', 'any', 'none']\n",
        "\n",
        "# Compute label counts\n",
        "label_counts = train_df[label_columns].sum()\n",
        "total_samples = len(train_df)\n",
        "\n",
        "# Calculate pos_weight: inverse of frequency\n",
        "pos_weights = (total_samples - label_counts) / label_counts\n",
        "pos_weights = torch.tensor(pos_weights.values, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"Computed pos_weights:\", pos_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hxoctlzPwZpP"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader\n",
        "train_dataset = HemorrhageDataset(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create the validation dataset & DataLoader\n",
        "val_dataset = HemorrhageDataset(val_df)  # Assuming val_df contains validation data\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # Define val_loader\n",
        "\n",
        "# Create the validation dataset & DataLoader\n",
        "test_dataset = HemorrhageDataset(test_df)  # Assuming val_df contains validation data\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Define val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJRMJ8KG1o3",
        "outputId": "65a86f75-f630-49aa-ac94-1716eaea247a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRl0E2SXwfQD",
        "outputId": "6cddd795-ce70-47ad-a0dd-603d2d081c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Batch Shape: torch.Size([32, 1, 224, 224]) torch.Size([32, 7])\n"
          ]
        }
      ],
      "source": [
        "# Display sample batch\n",
        "sample_images, sample_labels = next(iter(train_loader))\n",
        "print(\"Sample Batch Shape:\", sample_images.shape, sample_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TzXLtBJsBJ8",
        "outputId": "8c04936d-9bcb-464b-9df8-0f4d79b2256e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 120MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet-151 model\n",
        "model = models.resnet101(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kr7J14ePsEIn"
      },
      "outputs": [],
      "source": [
        "# Modify the first layer to accept 1-channel grayscale images\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XT2kHq5asVIe"
      },
      "outputs": [],
      "source": [
        "# Modify the last layer to match the number of labels (7 output classes)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 7)  # 7 classes for hemorrhage types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bUjdDIZAsXHt"
      },
      "outputs": [],
      "source": [
        "# Move model to GPU (if available)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fgbsrviKsZMq"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)  # Use BCE for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mdgTx5VMyhAD"
      },
      "outputs": [],
      "source": [
        "#trying a more aggressive decay for more epochs\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x_gcfoEOy_v7"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, best_thresholds=None):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    total_correct = [0] * 7\n",
        "    total_counts = [0] * 7\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "\n",
        "            # Apply per-label thresholds if provided, else default to 0.5\n",
        "            if best_thresholds is not None:\n",
        "                binary_preds = torch.zeros_like(probs)\n",
        "                for i, t in enumerate(best_thresholds):\n",
        "                    binary_preds[:, i] = (probs[:, i] > t).float()\n",
        "            else:\n",
        "                binary_preds = (probs > 0.5).float()\n",
        "\n",
        "            # Accumulate accuracy\n",
        "            for i in range(7):\n",
        "                total_correct[i] += (binary_preds[:, i] == labels[:, i]).sum().item()\n",
        "                total_counts[i] += labels.size(0)\n",
        "\n",
        "            all_preds.append(binary_preds.cpu())\n",
        "            all_targets.append(labels.cpu())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    class_accuracies = [100 * c / t if t != 0 else 0 for c, t in zip(total_correct, total_counts)]\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    return val_loss, class_accuracies, all_preds, all_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qCXHCRP8zxSs"
      },
      "outputs": [],
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "E4qrUzMfRGWo"
      },
      "outputs": [],
      "source": [
        "def optimize_thresholds(model, val_loader, criterion, thresholds=np.arange(0.1, 0.9, 0.1), label_names=None):\n",
        "    model.eval()\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            all_outputs.append(torch.sigmoid(outputs).cpu())\n",
        "            all_targets.append(labels.cpu())\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    best_thresholds = []\n",
        "    best_f1s = []\n",
        "\n",
        "    print(\"\\n🔎 Optimizing thresholds...\\n\")\n",
        "    for class_idx in range(all_outputs.shape[1]):\n",
        "        best_f1 = 0\n",
        "        best_thresh = 0.5\n",
        "        for t in thresholds:\n",
        "            preds = (all_outputs[:, class_idx] > t).astype(int)\n",
        "            f1 = f1_score(all_targets[:, class_idx], preds, zero_division=0)\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = t\n",
        "\n",
        "        best_thresholds.append(best_thresh)\n",
        "        best_f1s.append(best_f1)\n",
        "        label = label_names[class_idx] if label_names else f\"Class {class_idx}\"\n",
        "        print(f\"{label:<20} | Best Threshold: {best_thresh:.2f} | F1-score: {best_f1:.3f}\")\n",
        "\n",
        "    return best_thresholds, best_f1s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0a4d6d9",
        "outputId": "d696667a-429f-44bc-88d5-6dc63e5cc523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Starting Epoch 1/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 67.6630\n",
            "subdural Accuracy: 7.87%\n",
            "epidural Accuracy: 3.47%\n",
            "subarachnoid Accuracy: 95.33%\n",
            "intraparenchymal Accuracy: 5.87%\n",
            "intraventricular Accuracy: 95.33%\n",
            "any Accuracy: 16.93%\n",
            "none Accuracy: 16.40%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.07      1.00      0.13        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.00      0.00      0.00        35\n",
            "intraparenchymal       0.06      1.00      0.11        44\n",
            "intraventricular       0.00      0.00      0.00        35\n",
            "             any       0.16      1.00      0.28       123\n",
            "            none       0.00      0.00      0.00       627\n",
            "\n",
            "       micro avg       0.07      0.24      0.11       918\n",
            "       macro avg       0.04      0.57      0.08       918\n",
            "    weighted avg       0.03      0.24      0.05       918\n",
            "     samples avg       0.07      0.13      0.09       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.129\n",
            "epidural             | Best Threshold: 0.80 | F1-score: 0.012\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.000\n",
            "intraparenchymal     | Best Threshold: 0.10 | F1-score: 0.111\n",
            "intraventricular     | Best Threshold: 0.50 | F1-score: 0.000\n",
            "any                  | Best Threshold: 0.60 | F1-score: 0.290\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.091\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.129\n",
            "epidural             | Threshold: 0.80 | F1: 0.012\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.000\n",
            "intraparenchymal     | Threshold: 0.10 | F1: 0.111\n",
            "intraventricular     | Threshold: 0.50 | F1: 0.000\n",
            "any                  | Threshold: 0.60 | F1: 0.290\n",
            "none                 | Threshold: 0.10 | F1: 0.091\n",
            "\n",
            "💾 New best F1 avg: 0.090 — thresholds saved!\n",
            "✅ Epoch 1 done — Avg Loss: 1.4689, Val Loss: 67.6630, Val Acc: 34.46%\n",
            "\n",
            "🔁 Starting Epoch 2/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 5.3216\n",
            "subdural Accuracy: 63.07%\n",
            "epidural Accuracy: 0.53%\n",
            "subarachnoid Accuracy: 42.40%\n",
            "intraparenchymal Accuracy: 41.73%\n",
            "intraventricular Accuracy: 42.00%\n",
            "any Accuracy: 55.07%\n",
            "none Accuracy: 83.60%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.03      0.16      0.05        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.06      0.74      0.11        35\n",
            "intraparenchymal       0.08      0.82      0.14        44\n",
            "intraventricular       0.07      0.94      0.13        35\n",
            "             any       0.24      0.79      0.37       123\n",
            "            none       0.84      1.00      0.91       627\n",
            "\n",
            "       micro avg       0.24      0.91      0.37       918\n",
            "       macro avg       0.19      0.78      0.25       918\n",
            "    weighted avg       0.61      0.91      0.69       918\n",
            "     samples avg       0.26      0.95      0.39       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.10 | F1-score: 0.125\n",
            "epidural             | Best Threshold: 0.10 | F1-score: 0.011\n",
            "subarachnoid         | Best Threshold: 0.40 | F1-score: 0.109\n",
            "intraparenchymal     | Best Threshold: 0.10 | F1-score: 0.138\n",
            "intraventricular     | Best Threshold: 0.50 | F1-score: 0.129\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.367\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.10 | F1: 0.125\n",
            "epidural             | Threshold: 0.10 | F1: 0.011\n",
            "subarachnoid         | Threshold: 0.40 | F1: 0.109\n",
            "intraparenchymal     | Threshold: 0.10 | F1: 0.138\n",
            "intraventricular     | Threshold: 0.50 | F1: 0.129\n",
            "any                  | Threshold: 0.50 | F1: 0.367\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "\n",
            "💾 New best F1 avg: 0.256 — thresholds saved!\n",
            "✅ Epoch 2 done — Avg Loss: 1.2199, Val Loss: 5.3216, Val Acc: 46.91%\n",
            "\n",
            "🔁 Starting Epoch 3/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.2843\n",
            "subdural Accuracy: 22.67%\n",
            "epidural Accuracy: 0.53%\n",
            "subarachnoid Accuracy: 4.67%\n",
            "intraparenchymal Accuracy: 73.07%\n",
            "intraventricular Accuracy: 16.40%\n",
            "any Accuracy: 27.20%\n",
            "none Accuracy: 26.80%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.08      0.98      0.14        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.05      1.00      0.09        35\n",
            "intraparenchymal       0.13      0.66      0.22        44\n",
            "intraventricular       0.05      1.00      0.10        35\n",
            "             any       0.18      0.99      0.31       123\n",
            "            none       1.00      0.12      0.22       627\n",
            "\n",
            "       micro avg       0.09      0.38      0.15       918\n",
            "       macro avg       0.21      0.82      0.16       918\n",
            "    weighted avg       0.72      0.38      0.22       918\n",
            "     samples avg       0.10      0.26      0.14       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.50 | F1-score: 0.144\n",
            "epidural             | Best Threshold: 0.10 | F1-score: 0.011\n",
            "subarachnoid         | Best Threshold: 0.10 | F1-score: 0.089\n",
            "intraparenchymal     | Best Threshold: 0.50 | F1-score: 0.232\n",
            "intraventricular     | Best Threshold: 0.50 | F1-score: 0.101\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.310\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.50 | F1: 0.144\n",
            "epidural             | Threshold: 0.10 | F1: 0.011\n",
            "subarachnoid         | Threshold: 0.10 | F1: 0.089\n",
            "intraparenchymal     | Threshold: 0.50 | F1: 0.232\n",
            "intraventricular     | Threshold: 0.50 | F1: 0.101\n",
            "any                  | Threshold: 0.50 | F1: 0.310\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "\n",
            "💾 New best F1 avg: 0.257 — thresholds saved!\n",
            "✅ Epoch 3 done — Avg Loss: 1.2271, Val Loss: 1.2843, Val Acc: 24.48%\n",
            "\n",
            "🔁 Starting Epoch 4/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.1590\n",
            "subdural Accuracy: 6.67%\n",
            "epidural Accuracy: 0.53%\n",
            "subarachnoid Accuracy: 7.60%\n",
            "intraparenchymal Accuracy: 5.87%\n",
            "intraventricular Accuracy: 4.67%\n",
            "any Accuracy: 16.40%\n",
            "none Accuracy: 16.40%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.07      1.00      0.12        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.05      1.00      0.09        35\n",
            "intraparenchymal       0.06      1.00      0.11        44\n",
            "intraventricular       0.05      1.00      0.09        35\n",
            "             any       0.16      1.00      0.28       123\n",
            "            none       0.00      0.00      0.00       627\n",
            "\n",
            "       micro avg       0.06      0.32      0.11       918\n",
            "       macro avg       0.06      0.86      0.10       918\n",
            "    weighted avg       0.03      0.32      0.06       918\n",
            "     samples avg       0.06      0.16      0.09       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.10 | F1-score: 0.125\n",
            "epidural             | Best Threshold: 0.10 | F1-score: 0.011\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.091\n",
            "intraparenchymal     | Best Threshold: 0.10 | F1-score: 0.111\n",
            "intraventricular     | Best Threshold: 0.10 | F1-score: 0.089\n",
            "any                  | Best Threshold: 0.10 | F1-score: 0.282\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.10 | F1: 0.125\n",
            "epidural             | Threshold: 0.10 | F1: 0.011\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.091\n",
            "intraparenchymal     | Threshold: 0.10 | F1: 0.111\n",
            "intraventricular     | Threshold: 0.10 | F1: 0.089\n",
            "any                  | Threshold: 0.10 | F1: 0.282\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "✅ Epoch 4 done — Avg Loss: 1.1624, Val Loss: 1.1590, Val Acc: 8.30%\n",
            "\n",
            "🔁 Starting Epoch 5/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.1070\n",
            "subdural Accuracy: 22.40%\n",
            "epidural Accuracy: 22.93%\n",
            "subarachnoid Accuracy: 16.27%\n",
            "intraparenchymal Accuracy: 27.33%\n",
            "intraventricular Accuracy: 24.53%\n",
            "any Accuracy: 36.40%\n",
            "none Accuracy: 35.07%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.08      0.96      0.14        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.05      0.97      0.10        35\n",
            "intraparenchymal       0.07      0.98      0.14        44\n",
            "intraventricular       0.06      1.00      0.11        35\n",
            "             any       0.20      0.96      0.33       123\n",
            "            none       0.97      0.23      0.37       627\n",
            "\n",
            "       micro avg       0.11      0.47      0.18       918\n",
            "       macro avg       0.20      0.87      0.17       918\n",
            "    weighted avg       0.70      0.47      0.32       918\n",
            "     samples avg       0.21      0.35      0.25       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.205\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.014\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.099\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.242\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.189\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.331\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.205\n",
            "epidural             | Threshold: 0.50 | F1: 0.014\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.099\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.242\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.189\n",
            "any                  | Threshold: 0.50 | F1: 0.331\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "\n",
            "💾 New best F1 avg: 0.284 — thresholds saved!\n",
            "✅ Epoch 5 done — Avg Loss: 1.1023, Val Loss: 1.1070, Val Acc: 26.42%\n",
            "\n",
            "🔁 Starting Epoch 6/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.1019\n",
            "subdural Accuracy: 19.47%\n",
            "epidural Accuracy: 28.93%\n",
            "subarachnoid Accuracy: 26.67%\n",
            "intraparenchymal Accuracy: 32.80%\n",
            "intraventricular Accuracy: 29.60%\n",
            "any Accuracy: 36.80%\n",
            "none Accuracy: 34.93%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.07      0.94      0.13        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.06      0.94      0.11        35\n",
            "intraparenchymal       0.08      0.98      0.15        44\n",
            "intraventricular       0.06      0.91      0.11        35\n",
            "             any       0.20      0.95      0.33       123\n",
            "            none       0.95      0.23      0.37       627\n",
            "\n",
            "       micro avg       0.12      0.46      0.19       918\n",
            "       macro avg       0.20      0.85      0.17       918\n",
            "    weighted avg       0.69      0.46      0.32       918\n",
            "     samples avg       0.22      0.35      0.26       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.202\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.015\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.103\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.235\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.152\n",
            "any                  | Best Threshold: 0.60 | F1-score: 0.432\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.202\n",
            "epidural             | Threshold: 0.50 | F1: 0.015\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.103\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.235\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.152\n",
            "any                  | Threshold: 0.60 | F1: 0.432\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "\n",
            "💾 New best F1 avg: 0.293 — thresholds saved!\n",
            "✅ Epoch 6 done — Avg Loss: 1.0603, Val Loss: 1.1019, Val Acc: 29.89%\n",
            "\n",
            "🔁 Starting Epoch 7/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 2.1128\n",
            "subdural Accuracy: 70.80%\n",
            "epidural Accuracy: 65.87%\n",
            "subarachnoid Accuracy: 53.20%\n",
            "intraparenchymal Accuracy: 75.20%\n",
            "intraventricular Accuracy: 67.60%\n",
            "any Accuracy: 70.67%\n",
            "none Accuracy: 63.73%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.10      0.44      0.17        50\n",
            "        epidural       0.01      0.75      0.02         4\n",
            "    subarachnoid       0.06      0.66      0.12        35\n",
            "intraparenchymal       0.11      0.43      0.17        44\n",
            "intraventricular       0.08      0.57      0.14        35\n",
            "             any       0.28      0.49      0.35       123\n",
            "            none       0.87      0.67      0.75       627\n",
            "\n",
            "       micro avg       0.29      0.62      0.39       918\n",
            "       macro avg       0.22      0.57      0.25       918\n",
            "    weighted avg       0.65      0.62      0.59       918\n",
            "     samples avg       0.54      0.64      0.57       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.186\n",
            "epidural             | Best Threshold: 0.60 | F1-score: 0.042\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.115\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.186\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.231\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.367\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.186\n",
            "epidural             | Threshold: 0.60 | F1: 0.042\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.115\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.186\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.231\n",
            "any                  | Threshold: 0.50 | F1: 0.367\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "✅ Epoch 7 done — Avg Loss: 1.0761, Val Loss: 2.1128, Val Acc: 66.72%\n",
            "\n",
            "🔁 Starting Epoch 8/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0043\n",
            "subdural Accuracy: 58.67%\n",
            "epidural Accuracy: 32.67%\n",
            "subarachnoid Accuracy: 56.80%\n",
            "intraparenchymal Accuracy: 59.73%\n",
            "intraventricular Accuracy: 54.67%\n",
            "any Accuracy: 66.00%\n",
            "none Accuracy: 62.27%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.12      0.80      0.21        50\n",
            "        epidural       0.01      1.00      0.02         4\n",
            "    subarachnoid       0.09      0.86      0.16        35\n",
            "intraparenchymal       0.12      0.93      0.21        44\n",
            "intraventricular       0.09      0.91      0.16        35\n",
            "             any       0.31      0.85      0.45       123\n",
            "            none       0.96      0.57      0.72       627\n",
            "\n",
            "       micro avg       0.23      0.67      0.35       918\n",
            "       macro avg       0.24      0.85      0.27       918\n",
            "    weighted avg       0.71      0.67      0.58       918\n",
            "     samples avg       0.45      0.62      0.50       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.50 | F1-score: 0.210\n",
            "epidural             | Best Threshold: 0.60 | F1-score: 0.018\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.156\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.266\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.207\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.444\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.911\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.50 | F1: 0.210\n",
            "epidural             | Threshold: 0.60 | F1: 0.018\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.156\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.266\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.207\n",
            "any                  | Threshold: 0.50 | F1: 0.444\n",
            "none                 | Threshold: 0.10 | F1: 0.911\n",
            "\n",
            "💾 New best F1 avg: 0.316 — thresholds saved!\n",
            "✅ Epoch 8 done — Avg Loss: 1.0461, Val Loss: 1.0043, Val Acc: 55.83%\n",
            "\n",
            "🔁 Starting Epoch 9/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0533\n",
            "subdural Accuracy: 66.13%\n",
            "epidural Accuracy: 46.40%\n",
            "subarachnoid Accuracy: 43.73%\n",
            "intraparenchymal Accuracy: 72.00%\n",
            "intraventricular Accuracy: 58.53%\n",
            "any Accuracy: 69.33%\n",
            "none Accuracy: 65.33%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.11      0.56      0.18        50\n",
            "        epidural       0.01      1.00      0.02         4\n",
            "    subarachnoid       0.07      0.86      0.12        35\n",
            "intraparenchymal       0.15      0.84      0.26        44\n",
            "intraventricular       0.09      0.91      0.17        35\n",
            "             any       0.32      0.77      0.45       123\n",
            "            none       0.94      0.63      0.75       627\n",
            "\n",
            "       micro avg       0.26      0.67      0.37       918\n",
            "       macro avg       0.24      0.80      0.28       918\n",
            "    weighted avg       0.70      0.67      0.61       918\n",
            "     samples avg       0.45      0.65      0.51       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.50 | F1-score: 0.179\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.020\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.128\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.267\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.198\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.436\n",
            "none                 | Best Threshold: 0.40 | F1-score: 0.912\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.50 | F1: 0.179\n",
            "epidural             | Threshold: 0.50 | F1: 0.020\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.128\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.267\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.198\n",
            "any                  | Threshold: 0.50 | F1: 0.436\n",
            "none                 | Threshold: 0.40 | F1: 0.912\n",
            "✅ Epoch 9 done — Avg Loss: 1.0543, Val Loss: 1.0533, Val Acc: 60.21%\n",
            "\n",
            "🔁 Starting Epoch 10/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0308\n",
            "subdural Accuracy: 86.80%\n",
            "epidural Accuracy: 80.53%\n",
            "subarachnoid Accuracy: 86.53%\n",
            "intraparenchymal Accuracy: 89.73%\n",
            "intraventricular Accuracy: 88.80%\n",
            "any Accuracy: 85.60%\n",
            "none Accuracy: 85.73%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.20      0.32      0.24        50\n",
            "        epidural       0.02      0.75      0.04         4\n",
            "    subarachnoid       0.19      0.57      0.28        35\n",
            "intraparenchymal       0.26      0.41      0.32        44\n",
            "intraventricular       0.22      0.57      0.32        35\n",
            "             any       0.58      0.44      0.50       123\n",
            "            none       0.90      0.93      0.92       627\n",
            "\n",
            "       micro avg       0.58      0.78      0.66       918\n",
            "       macro avg       0.34      0.57      0.37       918\n",
            "    weighted avg       0.73      0.78      0.74       918\n",
            "     samples avg       0.79      0.85      0.81       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.40 | F1-score: 0.220\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.039\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.284\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.342\n",
            "intraventricular     | Best Threshold: 0.50 | F1-score: 0.341\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.466\n",
            "none                 | Best Threshold: 0.40 | F1-score: 0.920\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.40 | F1: 0.220\n",
            "epidural             | Threshold: 0.50 | F1: 0.039\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.284\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.342\n",
            "intraventricular     | Threshold: 0.50 | F1: 0.341\n",
            "any                  | Threshold: 0.50 | F1: 0.466\n",
            "none                 | Threshold: 0.40 | F1: 0.920\n",
            "\n",
            "💾 New best F1 avg: 0.373 — thresholds saved!\n",
            "✅ Epoch 10 done — Avg Loss: 1.0035, Val Loss: 1.0308, Val Acc: 86.25%\n",
            "\n",
            "🔁 Starting Epoch 11/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.7714\n",
            "subdural Accuracy: 35.47%\n",
            "epidural Accuracy: 34.27%\n",
            "subarachnoid Accuracy: 32.80%\n",
            "intraparenchymal Accuracy: 38.67%\n",
            "intraventricular Accuracy: 37.20%\n",
            "any Accuracy: 42.80%\n",
            "none Accuracy: 42.53%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.09      0.98      0.17        50\n",
            "        epidural       0.01      1.00      0.02         4\n",
            "    subarachnoid       0.06      0.94      0.12        35\n",
            "intraparenchymal       0.08      0.95      0.15        44\n",
            "intraventricular       0.07      0.97      0.13        35\n",
            "             any       0.22      0.97      0.36       123\n",
            "            none       0.98      0.32      0.48       627\n",
            "\n",
            "       micro avg       0.15      0.52      0.23       918\n",
            "       macro avg       0.22      0.88      0.20       918\n",
            "    weighted avg       0.71      0.52      0.40       918\n",
            "     samples avg       0.32      0.42      0.35       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.80 | F1-score: 0.196\n",
            "epidural             | Best Threshold: 0.70 | F1-score: 0.021\n",
            "subarachnoid         | Best Threshold: 0.80 | F1-score: 0.142\n",
            "intraparenchymal     | Best Threshold: 0.80 | F1-score: 0.197\n",
            "intraventricular     | Best Threshold: 0.80 | F1-score: 0.148\n",
            "any                  | Best Threshold: 0.80 | F1-score: 0.407\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.774\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.80 | F1: 0.196\n",
            "epidural             | Threshold: 0.70 | F1: 0.021\n",
            "subarachnoid         | Threshold: 0.80 | F1: 0.142\n",
            "intraparenchymal     | Threshold: 0.80 | F1: 0.197\n",
            "intraventricular     | Threshold: 0.80 | F1: 0.148\n",
            "any                  | Threshold: 0.80 | F1: 0.407\n",
            "none                 | Threshold: 0.10 | F1: 0.774\n",
            "✅ Epoch 11 done — Avg Loss: 0.9142, Val Loss: 1.7714, Val Acc: 37.68%\n",
            "\n",
            "🔁 Starting Epoch 12/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0816\n",
            "subdural Accuracy: 35.60%\n",
            "epidural Accuracy: 21.33%\n",
            "subarachnoid Accuracy: 37.07%\n",
            "intraparenchymal Accuracy: 45.60%\n",
            "intraventricular Accuracy: 41.07%\n",
            "any Accuracy: 40.27%\n",
            "none Accuracy: 39.47%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.09      0.90      0.16        50\n",
            "        epidural       0.01      1.00      0.01         4\n",
            "    subarachnoid       0.06      0.89      0.12        35\n",
            "intraparenchymal       0.09      0.91      0.16        44\n",
            "intraventricular       0.07      0.89      0.12        35\n",
            "             any       0.20      0.91      0.33       123\n",
            "            none       0.94      0.29      0.45       627\n",
            "\n",
            "       micro avg       0.14      0.49      0.21       918\n",
            "       macro avg       0.21      0.83      0.19       918\n",
            "    weighted avg       0.69      0.49      0.38       918\n",
            "     samples avg       0.23      0.39      0.28       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.80 | F1-score: 0.262\n",
            "epidural             | Best Threshold: 0.60 | F1-score: 0.016\n",
            "subarachnoid         | Best Threshold: 0.70 | F1-score: 0.192\n",
            "intraparenchymal     | Best Threshold: 0.80 | F1-score: 0.327\n",
            "intraventricular     | Best Threshold: 0.70 | F1-score: 0.245\n",
            "any                  | Best Threshold: 0.70 | F1-score: 0.468\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.912\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.80 | F1: 0.262\n",
            "epidural             | Threshold: 0.60 | F1: 0.016\n",
            "subarachnoid         | Threshold: 0.70 | F1: 0.192\n",
            "intraparenchymal     | Threshold: 0.80 | F1: 0.327\n",
            "intraventricular     | Threshold: 0.70 | F1: 0.245\n",
            "any                  | Threshold: 0.70 | F1: 0.468\n",
            "none                 | Threshold: 0.10 | F1: 0.912\n",
            "✅ Epoch 12 done — Avg Loss: 0.9272, Val Loss: 1.0816, Val Acc: 37.20%\n",
            "\n",
            "🔁 Starting Epoch 13/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0891\n",
            "subdural Accuracy: 72.93%\n",
            "epidural Accuracy: 68.93%\n",
            "subarachnoid Accuracy: 75.07%\n",
            "intraparenchymal Accuracy: 77.47%\n",
            "intraventricular Accuracy: 77.47%\n",
            "any Accuracy: 72.80%\n",
            "none Accuracy: 72.53%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.13      0.54      0.21        50\n",
            "        epidural       0.01      0.50      0.02         4\n",
            "    subarachnoid       0.09      0.46      0.15        35\n",
            "intraparenchymal       0.13      0.52      0.21        44\n",
            "intraventricular       0.13      0.69      0.22        35\n",
            "             any       0.32      0.59      0.41       123\n",
            "            none       0.90      0.75      0.82       627\n",
            "\n",
            "       micro avg       0.37      0.69      0.48       918\n",
            "       macro avg       0.25      0.58      0.29       918\n",
            "    weighted avg       0.68      0.69      0.65       918\n",
            "     samples avg       0.62      0.72      0.65       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.50 | F1-score: 0.246\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.024\n",
            "subarachnoid         | Best Threshold: 0.40 | F1-score: 0.143\n",
            "intraparenchymal     | Best Threshold: 0.50 | F1-score: 0.250\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.236\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.421\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.903\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.50 | F1: 0.246\n",
            "epidural             | Threshold: 0.50 | F1: 0.024\n",
            "subarachnoid         | Threshold: 0.40 | F1: 0.143\n",
            "intraparenchymal     | Threshold: 0.50 | F1: 0.250\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.236\n",
            "any                  | Threshold: 0.50 | F1: 0.421\n",
            "none                 | Threshold: 0.10 | F1: 0.903\n",
            "✅ Epoch 13 done — Avg Loss: 0.8867, Val Loss: 1.0891, Val Acc: 73.89%\n",
            "\n",
            "🔁 Starting Epoch 14/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 1.0417\n",
            "subdural Accuracy: 87.73%\n",
            "epidural Accuracy: 84.93%\n",
            "subarachnoid Accuracy: 92.00%\n",
            "intraparenchymal Accuracy: 91.87%\n",
            "intraventricular Accuracy: 93.33%\n",
            "any Accuracy: 86.93%\n",
            "none Accuracy: 86.93%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.22      0.34      0.27        50\n",
            "        epidural       0.03      0.75      0.05         4\n",
            "    subarachnoid       0.24      0.34      0.29        35\n",
            "intraparenchymal       0.30      0.30      0.30        44\n",
            "intraventricular       0.33      0.43      0.38        35\n",
            "             any       0.68      0.38      0.49       123\n",
            "            none       0.89      0.96      0.93       627\n",
            "\n",
            "       micro avg       0.66      0.78      0.71       918\n",
            "       macro avg       0.39      0.50      0.38       918\n",
            "    weighted avg       0.75      0.78      0.75       918\n",
            "     samples avg       0.81      0.86      0.82       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.311\n",
            "epidural             | Best Threshold: 0.30 | F1-score: 0.017\n",
            "subarachnoid         | Best Threshold: 0.50 | F1-score: 0.238\n",
            "intraparenchymal     | Best Threshold: 0.40 | F1-score: 0.397\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.329\n",
            "any                  | Best Threshold: 0.40 | F1-score: 0.584\n",
            "none                 | Best Threshold: 0.40 | F1-score: 0.924\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.311\n",
            "epidural             | Threshold: 0.30 | F1: 0.017\n",
            "subarachnoid         | Threshold: 0.50 | F1: 0.238\n",
            "intraparenchymal     | Threshold: 0.40 | F1: 0.397\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.329\n",
            "any                  | Threshold: 0.40 | F1: 0.584\n",
            "none                 | Threshold: 0.40 | F1: 0.924\n",
            "\n",
            "💾 New best F1 avg: 0.400 — thresholds saved!\n",
            "✅ Epoch 14 done — Avg Loss: 0.8650, Val Loss: 1.0417, Val Acc: 89.10%\n",
            "\n",
            "🔁 Starting Epoch 15/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.8644\n",
            "subdural Accuracy: 60.53%\n",
            "epidural Accuracy: 47.20%\n",
            "subarachnoid Accuracy: 64.40%\n",
            "intraparenchymal Accuracy: 66.27%\n",
            "intraventricular Accuracy: 66.13%\n",
            "any Accuracy: 66.93%\n",
            "none Accuracy: 66.40%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.13      0.86      0.23        50\n",
            "        epidural       0.01      1.00      0.02         4\n",
            "    subarachnoid       0.11      0.91      0.19        35\n",
            "intraparenchymal       0.14      0.93      0.24        44\n",
            "intraventricular       0.11      0.89      0.20        35\n",
            "             any       0.32      0.90      0.47       123\n",
            "            none       0.97      0.62      0.75       627\n",
            "\n",
            "       micro avg       0.28      0.71      0.40       918\n",
            "       macro avg       0.26      0.87      0.30       918\n",
            "    weighted avg       0.73      0.71      0.62       918\n",
            "     samples avg       0.52      0.66      0.56       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.80 | F1-score: 0.240\n",
            "epidural             | Best Threshold: 0.80 | F1-score: 0.038\n",
            "subarachnoid         | Best Threshold: 0.80 | F1-score: 0.246\n",
            "intraparenchymal     | Best Threshold: 0.80 | F1-score: 0.387\n",
            "intraventricular     | Best Threshold: 0.80 | F1-score: 0.333\n",
            "any                  | Best Threshold: 0.70 | F1-score: 0.517\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.916\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.80 | F1: 0.240\n",
            "epidural             | Threshold: 0.80 | F1: 0.038\n",
            "subarachnoid         | Threshold: 0.80 | F1: 0.246\n",
            "intraparenchymal     | Threshold: 0.80 | F1: 0.387\n",
            "intraventricular     | Threshold: 0.80 | F1: 0.333\n",
            "any                  | Threshold: 0.70 | F1: 0.517\n",
            "none                 | Threshold: 0.10 | F1: 0.916\n",
            "✅ Epoch 15 done — Avg Loss: 0.8541, Val Loss: 0.8644, Val Acc: 62.55%\n",
            "\n",
            "🔁 Starting Epoch 16/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.8997\n",
            "subdural Accuracy: 83.33%\n",
            "epidural Accuracy: 74.13%\n",
            "subarachnoid Accuracy: 87.73%\n",
            "intraparenchymal Accuracy: 90.93%\n",
            "intraventricular Accuracy: 90.13%\n",
            "any Accuracy: 85.33%\n",
            "none Accuracy: 86.00%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.18      0.44      0.26        50\n",
            "        epidural       0.02      1.00      0.04         4\n",
            "    subarachnoid       0.16      0.40      0.23        35\n",
            "intraparenchymal       0.35      0.66      0.46        44\n",
            "intraventricular       0.27      0.63      0.37        35\n",
            "             any       0.55      0.54      0.55       123\n",
            "            none       0.91      0.92      0.92       627\n",
            "\n",
            "       micro avg       0.56      0.80      0.66       918\n",
            "       macro avg       0.35      0.66      0.40       918\n",
            "    weighted avg       0.74      0.80      0.76       918\n",
            "     samples avg       0.76      0.85      0.79       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.290\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.028\n",
            "subarachnoid         | Best Threshold: 0.60 | F1-score: 0.316\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.476\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.388\n",
            "any                  | Best Threshold: 0.50 | F1-score: 0.604\n",
            "none                 | Best Threshold: 0.30 | F1-score: 0.930\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.290\n",
            "epidural             | Threshold: 0.50 | F1: 0.028\n",
            "subarachnoid         | Threshold: 0.60 | F1: 0.316\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.476\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.388\n",
            "any                  | Threshold: 0.50 | F1: 0.604\n",
            "none                 | Threshold: 0.30 | F1: 0.930\n",
            "\n",
            "💾 New best F1 avg: 0.433 — thresholds saved!\n",
            "✅ Epoch 16 done — Avg Loss: 0.8252, Val Loss: 0.8997, Val Acc: 85.37%\n",
            "\n",
            "🔁 Starting Epoch 17/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.8825\n",
            "subdural Accuracy: 77.33%\n",
            "epidural Accuracy: 54.80%\n",
            "subarachnoid Accuracy: 80.27%\n",
            "intraparenchymal Accuracy: 83.60%\n",
            "intraventricular Accuracy: 85.60%\n",
            "any Accuracy: 81.07%\n",
            "none Accuracy: 80.93%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.16      0.58      0.25        50\n",
            "        epidural       0.01      0.75      0.02         4\n",
            "    subarachnoid       0.14      0.63      0.23        35\n",
            "intraparenchymal       0.23      0.77      0.36        44\n",
            "intraventricular       0.21      0.74      0.33        35\n",
            "             any       0.45      0.70      0.55       123\n",
            "            none       0.93      0.83      0.88       627\n",
            "\n",
            "       micro avg       0.42      0.79      0.55       918\n",
            "       macro avg       0.30      0.72      0.37       918\n",
            "    weighted avg       0.73      0.79      0.73       918\n",
            "     samples avg       0.64      0.80      0.69       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.70 | F1-score: 0.311\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.024\n",
            "subarachnoid         | Best Threshold: 0.70 | F1-score: 0.304\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.479\n",
            "intraventricular     | Best Threshold: 0.80 | F1-score: 0.406\n",
            "any                  | Best Threshold: 0.60 | F1-score: 0.591\n",
            "none                 | Best Threshold: 0.20 | F1-score: 0.929\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.70 | F1: 0.311\n",
            "epidural             | Threshold: 0.50 | F1: 0.024\n",
            "subarachnoid         | Threshold: 0.70 | F1: 0.304\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.479\n",
            "intraventricular     | Threshold: 0.80 | F1: 0.406\n",
            "any                  | Threshold: 0.60 | F1: 0.591\n",
            "none                 | Threshold: 0.20 | F1: 0.929\n",
            "\n",
            "💾 New best F1 avg: 0.435 — thresholds saved!\n",
            "✅ Epoch 17 done — Avg Loss: 0.7637, Val Loss: 0.8825, Val Acc: 77.66%\n",
            "\n",
            "🔁 Starting Epoch 18/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.8100\n",
            "subdural Accuracy: 72.27%\n",
            "epidural Accuracy: 60.53%\n",
            "subarachnoid Accuracy: 75.60%\n",
            "intraparenchymal Accuracy: 77.47%\n",
            "intraventricular Accuracy: 79.07%\n",
            "any Accuracy: 78.80%\n",
            "none Accuracy: 78.80%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.16      0.74      0.26        50\n",
            "        epidural       0.01      1.00      0.03         4\n",
            "    subarachnoid       0.14      0.80      0.23        35\n",
            "intraparenchymal       0.20      0.91      0.32        44\n",
            "intraventricular       0.16      0.86      0.28        35\n",
            "             any       0.43      0.84      0.56       123\n",
            "            none       0.96      0.78      0.86       627\n",
            "\n",
            "       micro avg       0.39      0.80      0.52       918\n",
            "       macro avg       0.29      0.85      0.36       918\n",
            "    weighted avg       0.74      0.80      0.71       918\n",
            "     samples avg       0.65      0.78      0.69       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.70 | F1-score: 0.304\n",
            "epidural             | Best Threshold: 0.80 | F1-score: 0.044\n",
            "subarachnoid         | Best Threshold: 0.70 | F1-score: 0.268\n",
            "intraparenchymal     | Best Threshold: 0.80 | F1-score: 0.453\n",
            "intraventricular     | Best Threshold: 0.80 | F1-score: 0.397\n",
            "any                  | Best Threshold: 0.80 | F1-score: 0.597\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.932\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.70 | F1: 0.304\n",
            "epidural             | Threshold: 0.80 | F1: 0.044\n",
            "subarachnoid         | Threshold: 0.70 | F1: 0.268\n",
            "intraparenchymal     | Threshold: 0.80 | F1: 0.453\n",
            "intraventricular     | Threshold: 0.80 | F1: 0.397\n",
            "any                  | Threshold: 0.80 | F1: 0.597\n",
            "none                 | Threshold: 0.10 | F1: 0.932\n",
            "✅ Epoch 18 done — Avg Loss: 0.7614, Val Loss: 0.8100, Val Acc: 74.65%\n",
            "\n",
            "🔁 Starting Epoch 19/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.8965\n",
            "subdural Accuracy: 77.33%\n",
            "epidural Accuracy: 62.00%\n",
            "subarachnoid Accuracy: 83.47%\n",
            "intraparenchymal Accuracy: 84.93%\n",
            "intraventricular Accuracy: 86.67%\n",
            "any Accuracy: 81.07%\n",
            "none Accuracy: 80.80%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.16      0.54      0.24        50\n",
            "        epidural       0.01      1.00      0.03         4\n",
            "    subarachnoid       0.16      0.60      0.25        35\n",
            "intraparenchymal       0.23      0.66      0.34        44\n",
            "intraventricular       0.21      0.69      0.32        35\n",
            "             any       0.45      0.67      0.54       123\n",
            "            none       0.93      0.84      0.88       627\n",
            "\n",
            "       micro avg       0.45      0.78      0.57       918\n",
            "       macro avg       0.31      0.71      0.37       918\n",
            "    weighted avg       0.73      0.78      0.72       918\n",
            "     samples avg       0.67      0.80      0.71       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.60 | F1-score: 0.309\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.026\n",
            "subarachnoid         | Best Threshold: 0.60 | F1-score: 0.311\n",
            "intraparenchymal     | Best Threshold: 0.70 | F1-score: 0.436\n",
            "intraventricular     | Best Threshold: 0.80 | F1-score: 0.347\n",
            "any                  | Best Threshold: 0.60 | F1-score: 0.563\n",
            "none                 | Best Threshold: 0.20 | F1-score: 0.931\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.60 | F1: 0.309\n",
            "epidural             | Threshold: 0.50 | F1: 0.026\n",
            "subarachnoid         | Threshold: 0.60 | F1: 0.311\n",
            "intraparenchymal     | Threshold: 0.70 | F1: 0.436\n",
            "intraventricular     | Threshold: 0.80 | F1: 0.347\n",
            "any                  | Threshold: 0.60 | F1: 0.563\n",
            "none                 | Threshold: 0.20 | F1: 0.931\n",
            "✅ Epoch 19 done — Avg Loss: 0.7832, Val Loss: 0.8965, Val Acc: 79.47%\n",
            "\n",
            "🔁 Starting Epoch 20/20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📉 Validation Loss: 0.9469\n",
            "subdural Accuracy: 77.47%\n",
            "epidural Accuracy: 66.53%\n",
            "subarachnoid Accuracy: 80.53%\n",
            "intraparenchymal Accuracy: 85.60%\n",
            "intraventricular Accuracy: 88.00%\n",
            "any Accuracy: 79.47%\n",
            "none Accuracy: 79.33%\n",
            "\n",
            "🧮 Classification Report (threshold = 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.15      0.50      0.23        50\n",
            "        epidural       0.01      0.50      0.02         4\n",
            "    subarachnoid       0.13      0.54      0.21        35\n",
            "intraparenchymal       0.26      0.80      0.39        44\n",
            "intraventricular       0.23      0.66      0.34        35\n",
            "             any       0.42      0.65      0.51       123\n",
            "            none       0.92      0.82      0.87       627\n",
            "\n",
            "       micro avg       0.45      0.76      0.57       918\n",
            "       macro avg       0.30      0.64      0.37       918\n",
            "    weighted avg       0.72      0.76      0.71       918\n",
            "     samples avg       0.67      0.79      0.71       918\n",
            "\n",
            "\n",
            "🔎 Optimizing thresholds...\n",
            "\n",
            "subdural             | Best Threshold: 0.50 | F1-score: 0.250\n",
            "epidural             | Best Threshold: 0.50 | F1-score: 0.029\n",
            "subarachnoid         | Best Threshold: 0.70 | F1-score: 0.286\n",
            "intraparenchymal     | Best Threshold: 0.60 | F1-score: 0.448\n",
            "intraventricular     | Best Threshold: 0.60 | F1-score: 0.400\n",
            "any                  | Best Threshold: 0.60 | F1-score: 0.509\n",
            "none                 | Best Threshold: 0.10 | F1-score: 0.916\n",
            "\n",
            "🎯 Best per-label thresholds this epoch:\n",
            "subdural             | Threshold: 0.50 | F1: 0.250\n",
            "epidural             | Threshold: 0.50 | F1: 0.029\n",
            "subarachnoid         | Threshold: 0.70 | F1: 0.286\n",
            "intraparenchymal     | Threshold: 0.60 | F1: 0.448\n",
            "intraventricular     | Threshold: 0.60 | F1: 0.400\n",
            "any                  | Threshold: 0.60 | F1: 0.509\n",
            "none                 | Threshold: 0.10 | F1: 0.916\n",
            "✅ Epoch 20 done — Avg Loss: 0.7708, Val Loss: 0.9469, Val Acc: 79.56%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "num_epochs = 16\n",
        "best_val_loss = float(\"inf\")\n",
        "best_avg_f1 = 0  # Track best average F1 across all labels\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n🔁 Starting Epoch {epoch + 1}/{num_epochs}...\")\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False)):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            log_msg = f\"Epoch {epoch + 1}/{num_epochs}, Batch {i + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\"\n",
        "            logging.info(log_msg)\n",
        "\n",
        "    scheduler.step()\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "    label_names = ['subdural', 'epidural', 'subarachnoid', 'intraparenchymal',\n",
        "                   'intraventricular', 'any', 'none']\n",
        "\n",
        "    # Run validation\n",
        "    val_loss, class_accuracies, preds, targets = validate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"\\n📉 Validation Loss: {val_loss:.4f}\")\n",
        "    for name, acc in zip(label_names, class_accuracies):\n",
        "        print(f\"{name} Accuracy: {acc:.2f}%\")\n",
        "\n",
        "    print(\"\\n🧮 Classification Report (threshold = 0.5):\")\n",
        "    print(classification_report(targets, preds, target_names=label_names, zero_division=0))\n",
        "\n",
        "    # Optimize thresholds and evaluate F1\n",
        "    best_thresholds, best_f1s = optimize_thresholds(model, val_loader, criterion, label_names=label_names)\n",
        "\n",
        "    print(\"\\n🎯 Best per-label thresholds this epoch:\")\n",
        "    for name, thresh, f1 in zip(label_names, best_thresholds, best_f1s):\n",
        "        print(f\"{name:<20} | Threshold: {thresh:.2f} | F1: {f1:.3f}\")\n",
        "\n",
        "    avg_f1 = np.mean(best_f1s)\n",
        "\n",
        "    # Save best thresholds if F1 improves\n",
        "    if avg_f1 > best_avg_f1:\n",
        "        best_avg_f1 = avg_f1\n",
        "        with open(\"best_thresholds.json\", \"w\") as f:\n",
        "            json.dump({name: float(t) for name, t in zip(label_names, best_thresholds)}, f)\n",
        "        print(f\"\\n💾 New best F1 avg: {avg_f1:.3f} — thresholds saved!\")\n",
        "\n",
        "    # Log and optionally save model\n",
        "    log_msg = f\"✅ Epoch {epoch + 1} done — Avg Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {np.mean(class_accuracies):.2f}%\"\n",
        "    logging.info(log_msg)\n",
        "    print(log_msg)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        logging.info(f\"📈 Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_resnet101.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC73Xl4ZxpCq",
        "outputId": "3fc22c1b-bf21-4745-e3d0-055b668af218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training images: 750\n",
            "Expected number of images: 750\n",
            "Image Batch Shape: torch.Size([32, 1, 224, 224])\n",
            "Label Batch Shape: torch.Size([32, 7])\n"
          ]
        }
      ],
      "source": [
        "#just double checking\n",
        "print(f\"Total training images: {len(train_dataset)}\")\n",
        "print(f\"Expected number of images: {len(train_df)}\")  # Should match 750\n",
        "\n",
        "sample_images, sample_labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Image Batch Shape: {sample_images.shape}\")  # Should be [batch_size, channels, 224, 224]\n",
        "print(f\"Label Batch Shape: {sample_labels.shape}\")  # Should be [batch_size, num_classes]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHlHVX6SQSUG",
        "outputId": "3296c008-04bc-4c02-a829-1a23730d6f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ResNet model\n",
        "model = models.resnet101(pretrained=False)  # Load model without pretrained weights\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Adjust for grayscale input\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 7)  # Assuming 7 output labels\n",
        "model = model.to(device)\n",
        "\n",
        "# Load best trained weights\n",
        "model.load_state_dict(torch.load(\"best_resnet101.pth\"))\n",
        "model.eval()  # Set to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHUMCTWuReAV",
        "outputId": "8c32426b-4110-4bed-93ff-5f663ba7933c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Test Loss: 0.6988, Mean Accuracy: 82.84%\n",
            "\n",
            "📊 Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        subdural       0.25      0.52      0.34        60\n",
            "        epidural       0.01      1.00      0.03         4\n",
            "    subarachnoid       0.22      0.63      0.33        35\n",
            "intraparenchymal       0.21      0.89      0.35        36\n",
            "intraventricular       0.28      0.73      0.41        30\n",
            "             any       0.52      0.79      0.63       126\n",
            "            none       0.91      0.93      0.92       624\n",
            "\n",
            "       micro avg       0.50      0.87      0.64       915\n",
            "       macro avg       0.35      0.78      0.43       915\n",
            "    weighted avg       0.74      0.87      0.78       915\n",
            "     samples avg       0.71      0.89      0.76       915\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load thresholds first\n",
        "import json\n",
        "\n",
        "label_names = ['subdural', 'epidural', 'subarachnoid', 'intraparenchymal',\n",
        "               'intraventricular', 'any', 'none']\n",
        "\n",
        "with open(\"best_thresholds.json\", \"r\") as f:\n",
        "    threshold_dict = json.load(f)\n",
        "\n",
        "best_thresholds = [threshold_dict[label] for label in label_names]\n",
        "\n",
        "# Now validate on the test set\n",
        "test_loss, test_accuracies, test_preds, test_targets = validate(\n",
        "    model, test_loader, criterion, best_thresholds=best_thresholds\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Test Loss: {test_loss:.4f}, Mean Accuracy: {np.mean(test_accuracies):.2f}%\")\n",
        "\n",
        "# Optional: Full classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(test_targets, test_preds, target_names=label_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "wG3ka2WEW6Eo",
        "outputId": "32a52ad3-442d-40a7-9901-564178ab7fae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(label_names, class_accuracies) # Store the bar objects\n",
        "plt.xlabel(\"Hemorrhage Type\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Accuracy per Hemorrhage Type\")\n",
        "plt.ylim(0, 100 + 10)  # Add extra space for text above bars\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add percentage text above bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f\"{yval:.2f}%\", ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}